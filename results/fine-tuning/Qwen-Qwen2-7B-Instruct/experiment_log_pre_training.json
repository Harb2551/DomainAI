{
  "experiment_id": ".-local_models-Qwen-Qwen2-7B-Instruct_20250707_024741",
  "model_name": "./local_models/Qwen-Qwen2-7B-Instruct",
  "timestamp": "2025-07-07T02:47:41.144277",
  "config": {
    "lora_config": {
      "r": 16,
      "lora_alpha": 32,
      "target_modules": "{'v_proj', 'down_proj', 'gate_proj', 'up_proj', 'k_proj', 'q_proj', 'o_proj'}",
      "lora_dropout": 0.1,
      "bias": "none",
      "task_type": "CAUSAL_LM"
    },
    "training_args": {
      "per_device_train_batch_size": 8,
      "per_device_eval_batch_size": 8,
      "gradient_accumulation_steps": 4,
      "effective_batch_size": 32,
      "num_train_epochs": 3,
      "learning_rate": 0.0002,
      "fp16": true,
      "gradient_checkpointing": false,
      "max_grad_norm": 1.0,
      "optimizer": "adamw_torch",
      "warmup_steps": 10,
      "eval_strategy": "epoch",
      "save_strategy": "epoch",
      "logging_steps": 1
    },
    "estimated_total_steps": 84
  },
  "metrics": {},
  "system_info": {
    "gpu_available": true,
    "gpu_count": 1,
    "gpu_info": [],
    "cuda_version": "12.6",
    "torch_version": "2.7.1+cu126",
    "python_version": "3.9.21",
    "cpu_count": 256,
    "memory_total_gb": 1006.93,
    "memory_available_gb": 988.35
  },
  "training_history": [],
  "dataset_info": {
    "train_size": 896,
    "val_size": 112,
    "total_size": 1008,
    "train_val_split": "896/112",
    "data_dir": "./",
    "sample_train_example": {
      "text_length": 163,
      "keys": [
        "text",
        "labels"
      ]
    }
  },
  "model_stats": {
    "trainable_params_detail": [
      {
        "name": "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight",
        "shape": [
          16,
          3584
        ],
        "dtype": "torch.float32",
        "requires_grad": true,
        "numel": 57344
      },
      {
        "name": "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight",
        "shape": [
          3584,
          16
        ],
        "dtype": "torch.float32",
        "requires_grad": true,
        "numel": 57344
      },
      {
        "name": "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight",
        "shape": [
          16,
          3584
        ],
        "dtype": "torch.float32",
        "requires_grad": true,
        "numel": 57344
      },
      {
        "name": "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight",
        "shape": [
          512,
          16
        ],
        "dtype": "torch.float32",
        "requires_grad": true,
        "numel": 8192
      },
      {
        "name": "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight",
        "shape": [
          16,
          3584
        ],
        "dtype": "torch.float32",
        "requires_grad": true,
        "numel": 57344
      }
    ],
    "total_trainable_params_verified": 392
  }
}